{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb20097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struktur kolom yang diharapkan oleh model telah berhasil dibuat.\n",
      "Total kolom: 42\n",
      "\n",
      "Memulai proses prediksi untuk semua provinsi...\n",
      "\n",
      "[SUCCESS] Prediksi berhasil dibuat dan disimpan di 'public\\predictions_2025.csv'\n",
      "File ini siap digunakan oleh aplikasi React Anda.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- KONFIGURASI: Ganti dengan path file Anda ---\n",
    "MODEL_PATH = 'waste_model.joblib' \n",
    "SCALER_PATH = 'scaler.joblib'\n",
    "TRAINING_DATA_PATH = 'data_provinsi.csv' \n",
    "OUTPUT_PATH = os.path.join('public', 'predictions_2025.csv')\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Fungsi untuk memeriksa keberadaan file\n",
    "def check_file_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[ERROR] File tidak ditemukan di path: '{os.path.abspath(path)}'.\")\n",
    "        print(\"Pastikan Anda menjalankan skrip ini dari direktori root proyek 'WasteSnap' dan path file sudah benar.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Validasi semua path input\n",
    "if not all([check_file_exists(p) for p in [MODEL_PATH, SCALER_PATH, TRAINING_DATA_PATH]]):\n",
    "    exit()\n",
    "\n",
    "# Muat model, scaler, dan data training\n",
    "rf_model = joblib.load(MODEL_PATH)\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "df_train = pd.read_csv(TRAINING_DATA_PATH)\n",
    "\n",
    "# --- INI ADALAH BAGIAN KUNCI UNTUK MEREPLIKASI PROSES TRAINING ---\n",
    "\n",
    "# 1. Pisahkan fitur (X) dari data training untuk membuat template\n",
    "X_train_template = df_train.drop(columns=['persentase'])\n",
    "\n",
    "# 2. Definisikan kolom kategori secara eksplisit\n",
    "categorical_features = ['nama_provinsi', 'jenis_sampah']\n",
    "\n",
    "# 3. Terapkan one-hot encoding dengan drop_first=True, SAMA SEPERTI SAAT TRAINING\n",
    "#    Ini adalah \"golden standard\" kolom kita.\n",
    "X_train_encoded_template = pd.get_dummies(X_train_template, columns=categorical_features, drop_first=True) # <-- PERUBAHAN KUNCI\n",
    "X_columns_standard = X_train_encoded_template.columns\n",
    "\n",
    "# 4. Dapatkan daftar unik provinsi dan jenis sampah untuk iterasi\n",
    "unique_provinces = sorted(list(df_train['nama_provinsi'].unique()))\n",
    "unique_waste_types = sorted(list(df_train['jenis_sampah'].unique()))\n",
    "\n",
    "print(\"Struktur kolom yang diharapkan oleh model telah berhasil dibuat.\")\n",
    "print(f\"Total kolom: {len(X_columns_standard)}\")\n",
    "print(\"\\nMemulai proses prediksi untuk semua provinsi...\")\n",
    "\n",
    "all_predictions = []\n",
    "prediction_year = 2025\n",
    "\n",
    "# Lakukan prediksi untuk setiap kombinasi\n",
    "for province_name in unique_provinces:\n",
    "    for waste_type in unique_waste_types:\n",
    "        # Buat DataFrame input mentah untuk satu baris prediksi\n",
    "        raw_input_df = pd.DataFrame([{'tahun': prediction_year, 'nama_provinsi': province_name, 'jenis_sampah': waste_type}])\n",
    "        \n",
    "        # Terapkan one-hot encoding DENGAN CARA YANG SAMA PERSIS (drop_first=True)\n",
    "        processed_input = pd.get_dummies(raw_input_df, columns=categorical_features, drop_first=True) # <-- PERUBAHAN KUNCI\n",
    "        \n",
    "        # REINDEX: Paksa DataFrame prediksi agar memiliki kolom yang persis sama\n",
    "        final_input = processed_input.reindex(columns=X_columns_standard, fill_value=0)\n",
    "        \n",
    "        # Prediksi dengan model\n",
    "        rf_pred_scaled = rf_model.predict(final_input)[0]\n",
    "        \n",
    "        # Kembalikan nilai prediksi ke skala aslinya\n",
    "        rf_pred_original = scaler.inverse_transform(np.array([[rf_pred_scaled]]))[0][0]\n",
    "        \n",
    "        # Tambahkan hasil prediksi ke daftar\n",
    "        all_predictions.append({\n",
    "            'tahun': prediction_year,\n",
    "            'nama_provinsi': province_name,\n",
    "            'jenis_sampah': waste_type,\n",
    "            'persentase': round(rf_pred_original, 4)\n",
    "        })\n",
    "\n",
    "# Buat DataFrame dari semua prediksi\n",
    "df_predictions = pd.DataFrame(all_predictions)\n",
    "\n",
    "# Pastikan direktori 'public' ada\n",
    "os.makedirs('public', exist_ok=True)\n",
    "\n",
    "# Simpan ke file CSV di folder public\n",
    "df_predictions.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"\\n[SUCCESS] Prediksi berhasil dibuat dan disimpan di '{OUTPUT_PATH}'\")\n",
    "print(\"File ini siap digunakan oleh aplikasi React Anda.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
